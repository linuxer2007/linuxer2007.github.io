<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rust并行 on </title>
    <link>/concurrency/</link>
    <description>Recent content in Rust并行 on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>osnudt@gmail.com (南明离火)</managingEditor>
    <webMaster>osnudt@gmail.com (南明离火)</webMaster>
    <lastBuildDate>Tue, 27 Jun 2023 14:44:16 +0800</lastBuildDate>
    <atom:link href="/concurrency/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>exmaple</title>
      <link>/concurrency/chapter01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>osnudt@gmail.com (南明离火)</author>
      <guid>/concurrency/chapter01/</guid>
      <description>在本章中，我们将完成本书的前期工作，确保覆盖到构建本书剩余部分所需的基础知识。本书介绍了在Rust编程语言中进行并行编程的内容。因此，理解现代计算硬件的基本情况非常重要。我们需要了解现代CPU的运行方式，内存总线如何影响CPU执行工作的能力，以及计算机能够同时执行多个任务的含义。此外，我们还将讨论验证Rust安装，并介绍生成本书关注的两种CPU架构的可执行文件。&#xA;通过本章的学习，我们将：&#xA;讨论CPU操作的高级模型 讨论计算机内存的高级模型 对Rust内存模型进行初步讨论 研究生成可运行的x86和ARM Rust程序 研究调试这些程序 技术要求 本章需要一台任何类型的现代计算机，可以在该计算机上安装Rust。具体细节将在下面详细介绍。感兴趣的读者可以选择投资于ARM开发板。我在写作时使用了树莓派3型号B。下面使用了Valgrind工具套件。许多操作系统捆绑了Valgrind软件包，但您可以在valgrind.org上找到有关您的系统的进一步安装说明。gdb和lldb工具通常与gcc和llvm编译器工具链一起安装和使用。&#xA;你可以在GitHub上找到本书项目的源代码：https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust。本章没有相关的源代码。&#xA;机器 本书中，不考虑具体的Rust技术，我们将尝试教授一种与现代并行计算机相对应的“机械同理心”。我们将涉及两种模型的并行性-并发内存操作和数据并行性。本书的大部分时间将花在并发内存操作上，这种并行性是多个CPU竞争操作共享可寻址内存的情况。数据并行性允许CPU能够同时处理单个或多个指令，操作多个字。我们会简要介绍数据并行性，但具体细节取决于CPU，而且所需的内部函数目前仅在基础语言中提供。幸运的是，作为一种具有现代库管理功能的系统语言，Rust可以轻松地引入适当的库并生成正确的指令，或者我们可以直接内联汇编代码。&#xA;关于并行机器算法的抽象构造的文献必须选择一种机器模型进行操作。并行随机访问机器（PRAM）在文献中很常见。在本书中，我们将重点关注两种具体的机器架构：&#xA;x86 ARM 选择这些机器是因为它们是常见的，并且每种机器都具有特定的属性，当我们到达第6章“原子 - 同步的基本操作”时将会很重要。实际机器与PRAM模型在重要方面有所偏差。最明显的是，实际机器具有有限数量的CPU和有限的RAM。内存位置不是每个CPU都可以均匀访问；事实上，缓存层次结构对计算机程序的性能有重要影响。这并不意味着PRAM是一个荒谬的简化，其他模型也不然。应该理解的是，在解决问题时，我们需要出于必要性划定抽象界限，进一步的细节并不能提高我们良好解决问题的能力。我们还必须理解我们自己工作的抽象与他人的抽象之间的关系，以便学习和分享。在本书中，我们将关注通过仔细测量、检查汇编代码和尝试其他实现方法来了解我们的机器的经验方法。这将与我们对机器的抽象模型相结合，该模型与今天的机器更具体相关，但在细节上仍然关注总缓存层、缓存大小、总线速度、微码版本等方面。如果需要并且感到有足够勇气，读者可以增加更多具体性。&#xA;CPU CPU是一种设备，解释一系列指令并在处理过程中操作存储设备和其他连接到它的设备。CPU的最简单模型——通常在本科计算机科学课程中首先介绍的模型——是CPU从某些难以捉摸的地方接收指令，执行解释，接收下一个指令，解释该指令，以此类推。CPU通过振荡器电路保持内部节奏，所有指令都需要一定数量的振荡脉冲或时钟周期才能执行。在一些CPU模型中，每条指令都需要相同数量的时钟周期来执行，而在另一些模型中，指令的周期数会有所不同。一些CPU指令修改寄存器，并且具有非常低的延迟，专用于CPU内置的但极其有限的内存位置。其他CPU指令修改主存储器RAM。其他指令在寄存器和RAM之间移动或复制信息，反之亦然。RAM（其读/写延迟比寄存器高得多，但更加丰富）以及其他存储设备（如SSD）通过专用总线连接到CPU。&#xA;这些总线的确切性质，它们的带宽和传输延迟，因机器架构而异。在某些系统上，RAM中的每个位置都是可寻址的——这意味着可以在可用的CPU中以恒定时间读取或写入。在其他系统中，情况并非如此——一些RAM是CPU本地的，而另一些是CPU远程的。一些指令控制特殊的硬件中断，导致内存范围被写入到其他总线连接的存储设备。大多数情况下，这些设备比RAM慢得多，而RAM本身比寄存器慢。&#xA;所有这一切都是为了解释，在CPU最简单的模型中，指令按顺序执行，指令可能会因等待读取或写入操作而在许多时钟周期内停顿。为此，重要的是要理解几乎所有CPU（尤其是本书中关注的CPU）都对其指令进行乱序执行。只要CPU能够证明两个指令序列明显地访问内存——也就是说它们不会互相干扰——那么CPU就是自由的，很可能会重新排序指令。这是使C语言关于未初始化内存的未定义行为变得有趣的事情之一。也许您程序的未来已经填充了内存，也可能没有。乱序执行使得对处理器行为的推理变得困难，但其好处是CPU可以通过推迟因某种内存访问而陷入停滞的指令序列来更快地执行程序。&#xA;在相同的精神下，大多数现代CPU（尤其是本书中关注的CPU）都执行分支预测。假设我们程序中的分支在执行时倾向于以相同的方式分支——例如，假设我们有一个功能标志测试，该测试被配置为在程序的整个生命周期内启用。执行分支预测的CPU将在等待其他停滞指令流的指令时猜测性地执行分支的一侧，该分支倾向于以某种方式分支。当分支指令序列赶上其分支测试时，如果测试按预测的方式进行，已经完成了大量工作，指令序列可以很好地跳过。不幸的是，如果分支预测错误，则必须拆除和丢弃所有这些先前的工作，并计算正确的分支，这非常昂贵。正是因为这个原因，您会发现那些担心其程序的细节性能特性的程序员往往会担心分支并试图将其移除。&#xA;所有这一切都需要大量的能源，重新排序指令以避免停滞或超前执行可能被丢弃的计算。高耗能意味着热量高，这又意味着需要冷却，这又意味着更多的能源消耗。这一切对技术文明的可持续性并不一定有益，这取决于如何生成所有这些电力以及浪费热量的位置。为此，许多现代CPU集成了某种功率缩放功能。一些CPU会延长其时钟脉冲之间的时间，这意味着它们在一定的时间内执行的指令比它们本来可以执行的要少。其他CPU则像平常一样快速前进，然后关闭一段时间，同时绘制最小的电力和冷却。构建和运行功率效率高的CPU的确切方法超出了本书的范围。重要的是要理解，由于所有这些原因，您的程序的执行速度将因CPU决定是否节约电力而在运行之间变化，其他一切都相等。在下一章中，当我们手动设置省电设置时，我们将看到这一点。&#xA;内存与缓存 CPU的存储器，正如上一节所提到的，是相当有限的。它仅限于一小部分通用寄存器中的词，以及在某些特殊情况下的特殊用途寄存器。寄存器非常快，由于它们的构造和芯片内位置，但它们不适合存储。现代计算机通过总线或多条总线连接到主存储器，这是一个非常大的随机可寻址字节块。这种随机地址性很重要，因为这意味着，与其他存储方式不同，从RAM中检索第0字节的成本与检索第10亿字节的成本并无差别。我们程序员无需进行任何古怪的技巧来确保我们的结构出现在RAM的前面，以便更快地检索或修改，而存储的物理位置对于旋转硬盘和磁带驱动器而言是一个紧迫的问题。我们的CPU与存储器的交互方式在不同平台上有所不同，接下来的讨论在很大程度上借鉴了Mark Batty在他2014年的著作《C11和C++11 并发模型》中的描述。&#xA;在一个暴露顺序一致的内存访问模型的计算机中，每个内存加载或存储都必须与其他内存加载或存储一起进行，包括在具有多个CPU或每个CPU多个执行线程的系统中。这限制了重要的优化——考虑在一个顺序一致的模型中绕过内存停滞的挑战——因此，我们将在本书中考虑的这两种处理器都不提供这种模型。由于这种模型的推理便利，它会以名称的形式出现在文献中，并且值得了解，特别是在学习原子性文献时。&#xA;x86平台的行为就好像它是顺序一致的，除了每个执行线程维护一个FIFO缓冲区用于写入在被刷新到主存储器之前。此外，还有一个全局锁用于协调执行线程之间的原子读取和写入。这里有很多内容需要理解。首先，我使用加载和存储这两个词来替换读取和写入，正如大多数文献所做的那样。普通的加载/存储和原子加载/存储之间还存在一种区别。原子加载/存储是特殊的，因为它们的效果可以在执行线程之间进行协调，允许以不同程度的保证进行协调。x86处理器平台提供了强制刷新写缓冲区的屏障指令，阻塞其他试图访问写入范围的主存储器的执行线程，直到刷新完成为止。这就是全局锁的目的。没有原子性，写入将会随意刷新。在x86平台上，对内存中可寻址位置的写入是一致的，这意味着它们是全局有序的，并且读取将按照写入的顺序看到该位置的值。与ARM相比，在x86上的工作原理非常简单——写入直接发生在主存储器中。&#xA;让我们来看一个例子。借鉴Batty的优秀论文，考虑这样一个设置：父线程将两个变量x和y设置为0，然后生成两个名为A和B的线程。线程A负责设置x然后将y设置为1，而线程B负责将x的值加载到一个称为thr_x的线程本地变量中，将y加载到一个称为thr_y的线程本地变量中。这看起来像是以下这样：&#xA;WRITE x := 0 WRITE y := 0 [A] WRITE x := 1 [A] WRITE y := 1 FLUSH A [B] READ x [B] WRITE thr_x := x [B] READ y [B] WRITE thr_y := y 在这个具体的例子中，thr_x == 1 并且 thr_y == 1。如果CPU按照不同的顺序刷新，那么这个结果可能会不同。例如，看看以下内容：</description>
    </item>
    <item>
      <title>顺序Rust性能和测试</title>
      <link>/concurrency/chapter02/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>osnudt@gmail.com (南明离火)</author>
      <guid>/concurrency/chapter02/</guid>
      <description>&amp;ldquo;先让它工作，然后让它变得美观，如果你真的，真的必须这样做，再让它变快。&amp;rdquo;&#xA;- Joe Armstrong&#xA;在前一章中，我们讨论了现代计算机体系结构的基础知识 - CPU及其功能，存储器层次结构及其相互作用。我们简要介绍了Rust程序的调试和性能分析。在本章中，我们将继续讨论这个问题，深入研究顺序Rust程序的性能特性，并暂时推迟对并发性能的考虑。我们还将讨论用于展示Rust程序适用性的测试技术。为什么在一本关于并行编程的书中，我们要专门为顺序程序撰写一整章的内容呢？我们在这里讨论的技术对于并行设置也是适用且至关重要的。我们在这里所获得的是对于快速和正确性的关注的实质部分 - 无需并行编程所带来的复杂性，不过，我们会适时讲述这个问题。还需要理解的是，快速并行代码的生成与快速顺序代码的生成是密不可分的。这是因为存在着我们将在整本书中处理的冷酷而严峻的数学现实。&#xA;到本章结束时，我们将会：&#xA;学习Amdahl和Gustafson定律 研究Rust标准库HashMap的内部机制 能够使用QuickCheck对替代HashMap实现进行随机验证 能够使用American Fuzzy Lop来证明其不会发生崩溃 使用Valgrind和Linux Perf来检查Rust软件的性能 技术要求 本章需要一个可用的Rust安装。验证您的安装细节已在第1章，即《初步 - 机器架构和开始使用Rust》中进行了介绍。这里将使用Valgrind套件工具。许多操作系统捆绑了valgrind软件包，但您可以在valgrind.org上找到有关您的系统的进一步安装说明。Linux Perf被使用，并且被许多Linux发行版捆绑在一起。本章所需的任何其他软件都作为本文的一部分安装。&#xA;您可以在GitHub上找到本书项目的源代码：https://github.com/PacktPublishing/Hands-On-Concurrency-with-Rust。本章的源代码位于Chapter02目录下。&#xA;收益递减 残酷的事实是，当将越来越多的并发计算资源应用于问题时，收益递减。执行并行计算意味着一些协调开销 - 创建新线程、分块数据以及在存在屏障或围栏时的内存总线问题，这取决于您的CPU。并行计算并非免费。考虑这个Hello, world!程序：&#xA;fn main() { println!(&amp;#34;GREETINGS, HUMANS&amp;#34;); } 很简单，对吧？编译并运行100次：&#xA;hello_worlds &amp;gt; rustc -C opt-level=3 sequential_hello_world.rs hello_worlds &amp;gt; time for i in {1..100}; do ./sequential_hello_world &amp;gt; /dev/null; done real 0m0.091s user 0m0.004s sys 0m0.012s 现在考虑基本相同的程序，但涉及生成线程的开销：&#xA;use std::thread; fn main() { thread::spawn(|| println!(&amp;#34;GREETINGS, HUMANS&amp;#34;)) .</description>
    </item>
  </channel>
</rss>
